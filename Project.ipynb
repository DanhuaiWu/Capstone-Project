{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: \n",
    "  ## Flowers Classification using Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPool2D, Dropout, Activation, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import urllib.request\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError\n",
    "# import socket  \n",
    "# socket.setdefaulttimeout(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection\n",
    "\n",
    "### Scrap images from http://www.image-net.org \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category={'Sunflower':'http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n11978961',\n",
    "          'Peony':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11719286',\n",
    "          'Nigella':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11736851',\n",
    "          'Spathiphyllum':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11792341',\n",
    "          'Ragged_robin':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11811706',\n",
    "          'Soapwort':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11814584',\n",
    "          'Ice_plant':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11821184',\n",
    "          'Spring_beauty':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11859472',\n",
    "          'African_daisy':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11925303',\n",
    "          'Cornflower':'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n11947802'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# import urllib.request\n",
    "# from urllib.request import Request, urlopen\n",
    "# from urllib.error import URLError\n",
    "# import socket  \n",
    "# socket.setdefaulttimeout(1)\n",
    "\n",
    "# with urllib.request.urlopen('http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n11978961') as sunflower:\n",
    "#     sunflower_html = sunflower.read().decode()\n",
    "    \n",
    "\n",
    "\n",
    "def get_urls(urls_links):\n",
    "    url_list=urllib.request.urlopen(urls_links).read().decode().split('\\r\\n')\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def download_images(urls_link,category_name):\n",
    "    if not os.path.exists(category_name):\n",
    "        os.makedirs(category_name)\n",
    "    count=1\n",
    "    url_list=get_urls(urls_link)\n",
    "    for url in url_list:\n",
    "        try:\n",
    "            path_name=str(category_name)+'/'+str(count)+'.'+str(category_name)+'.jpg'\n",
    "            urllib.request.urlretrieve(url,path_name)\n",
    "             \n",
    "            img=cv2.imread(path_name)\n",
    "            resized_image=cv2.resize(img,(100,100))\n",
    "            cv2.imwrite(path_name,resized_image)\n",
    "        except Exception as e:\n",
    "            print(str(count)+str(e))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cate in category:\n",
    "    download_images(category['cate'],cate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_image_dir='/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    img_label = img.split('.')[-2]\n",
    "    return img_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jpg_image_to_array(path):\n",
    "    \"\"\"\n",
    "  Loads JPEG image into 3D Numpy array of shape \n",
    "  (width, height, channels)\n",
    "  \"\"\"\n",
    "    img=Image.open(path)\n",
    "    img_arr=np.asarray(img).reshape((img.size[1], img.size[0],3))\n",
    "    return img_arr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_image_dataset(image_dir):\n",
    "#     img_dataset=[]\n",
    "#     for img in os.listdir(image_dir):\n",
    "#         try: \n",
    "#             img_peth=str(image_dir)+'/'+str(img)\n",
    "#             image_array=jpg_image_to_array(img_peth)\n",
    "#             label=label_img(img)\n",
    "#             img_dataset.append([image_array,label])  \n",
    "#         except Exception as e:\n",
    "#             print(str(e))\n",
    "# #     np.save('image_dataset.npy',img_dataset)\n",
    "# #     return img_dataset\n",
    "#     return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image_data_test2=create_image_dataset(all_image_dir)\n",
    "# image_data_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_list(image_dir):\n",
    "    img_dataset=[]\n",
    "    label_dataset=[]\n",
    "    for img in os.listdir(image_dir):\n",
    "        try: \n",
    "            img_path=str(image_dir)+'/'+str(img)\n",
    "            image_array=jpg_image_to_array(img_path)\n",
    "            label=label_img(img)\n",
    "            img_dataset.append([image_array])  \n",
    "#             label_dataset.append([label])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     np.save('image_dataset.npy',img_dataset)\n",
    "#     return img_dataset\n",
    "    return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/.DS_Store'\n",
      "cannot reshape array of size 16320 into shape (120,136,3)\n",
      "cannot reshape array of size 12100 into shape (110,110,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/370.Ragged_robin.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot reshape array of size 9216 into shape (96,96,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/438.Spring_beauty.jpg'\n",
      "cannot reshape array of size 90000 into shape (300,300,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/472.Sunflower.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/725.Spring_beauty.jpg'\n",
      "cannot reshape array of size 2700 into shape (60,45,3)\n",
      "cannot reshape array of size 36936 into shape (216,171,3)\n",
      "cannot reshape array of size 13440 into shape (120,112,3)\n"
     ]
    }
   ],
   "source": [
    "image_list=create_image_list(all_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8109, 1, 100, 100, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list_arr=np.array(image_list)\n",
    "image_list_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8109, 100, 100, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list_reshape=image_list_arr.reshape(8109,100,100,3)\n",
    "image_list_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label_list(image_dir):\n",
    "    img_dataset=[]\n",
    "    label_dataset=[]\n",
    "    for img in os.listdir(image_dir):\n",
    "        try: \n",
    "            img_path=str(image_dir)+'/'+str(img)\n",
    "            image_array=jpg_image_to_array(img_path)\n",
    "            label=label_img(img)\n",
    "#             img_dataset.append([image_array])  \n",
    "            label_dataset.append([label])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     np.save('image_dataset.npy',img_dataset)\n",
    "#     return img_dataset\n",
    "    return label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/.DS_Store'\n",
      "cannot reshape array of size 16320 into shape (120,136,3)\n",
      "cannot reshape array of size 12100 into shape (110,110,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/370.Ragged_robin.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot reshape array of size 9216 into shape (96,96,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/438.Spring_beauty.jpg'\n",
      "cannot reshape array of size 90000 into shape (300,300,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/472.Sunflower.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/GA/DSI_Plus/capstone_project/image_download/test/all_flower_image/725.Spring_beauty.jpg'\n",
      "cannot reshape array of size 2700 into shape (60,45,3)\n",
      "cannot reshape array of size 36936 into shape (216,171,3)\n",
      "cannot reshape array of size 13440 into shape (120,112,3)\n"
     ]
    }
   ],
   "source": [
    "label_list=create_label_list(all_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8109, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list_arr=np.array(label_list)\n",
    "label_list_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "a = image_list_arr\n",
    "b = label_list_arr\n",
    "\n",
    "c = list(zip(a, b))\n",
    "\n",
    "random.shuffle(c)\n",
    "\n",
    "a1, b1 = zip(*c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a2=np.array(a1)\n",
    "b2=np.array(b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8109, 100, 100, 3) (8109, 1)\n"
     ]
    }
   ],
   "source": [
    "a2=a2.reshape(8109, 100, 100, 3)\n",
    "print(a2.shape,b2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6487.200000000001"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8109*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=a2[:6487]\n",
    "X_test=a2[6487:]\n",
    "y_train=b2[:6487]\n",
    "y_test=b2[6487:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rescale=X_train/255\n",
    "X_test_rescale=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y_train_1hot = encoder.fit_transform(y_train)\n",
    "y_test_1hot=encoder.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 1, 0, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train_test11 = keras.utils.to_categorical(y_train_test1, 10)\n",
    "# y_test_test11 = keras.utils.to_categorical(y_test_test1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1 = Sequential([\n",
    "    Conv2D(50, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(150, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 98, 98, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 49, 49, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 47, 47, 100)       45100     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               6771328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 6,819,630\n",
      "Trainable params: 6,819,374\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn1.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.1),\n",
    "#               optimizer=Adam(lr=0.2),\n",
    "#               optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5189 samples, validate on 1298 samples\n",
      "Epoch 1/5\n",
      "5189/5189 [==============================] - 176s - loss: 2.0496 - acc: 0.3103 - val_loss: 2.0624 - val_acc: 0.3521\n",
      "Epoch 2/5\n",
      "5189/5189 [==============================] - 153s - loss: 1.6652 - acc: 0.4282 - val_loss: 1.9310 - val_acc: 0.2935\n",
      "Epoch 3/5\n",
      "5189/5189 [==============================] - 156s - loss: 1.4855 - acc: 0.4962 - val_loss: 1.6773 - val_acc: 0.4584\n",
      "Epoch 4/5\n",
      "5189/5189 [==============================] - 163s - loss: 1.3337 - acc: 0.5614 - val_loss: 1.5686 - val_acc: 0.4761\n",
      "Epoch 5/5\n",
      "5189/5189 [==============================] - 164s - loss: 1.1953 - acc: 0.6101 - val_loss: 1.5297 - val_acc: 0.4669\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c44e3b70>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.fit(X_train_rescale, y_train_1hot, validation_split=.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1622/1622 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy1 = cnn1.evaluate(X_test_rescale, y_test_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45314426648484502"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "number_of_conv   dropout     num_fillter    Dense   LR   epochs   train_acc   val_acc   test_acc\n",
    "    2               0.25       50 100        128   0.5     5       0.7          0.61       0.57\n",
    "    3               0.25       50 100 200    128   0.5     5       0.67         0.60       0.57 \n",
    "    2               0.5        50 100         64   0.2     5       0.49         0.53       0.58\n",
    "    2               0.5        50 100        128   0.2    20       0.85         0.63       0.63  \n",
    "    \n",
    "    \n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2 = Sequential([\n",
    "    Conv2D(50, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    Conv2D(100, (3, 3), activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(150, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 98, 98, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 49, 49, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 47, 47, 100)       45100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 47, 47, 100)       400       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               6771328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 6,820,030\n",
      "Trainable params: 6,819,574\n",
      "Non-trainable params: 456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import optimizers\n",
    "# sgd = optimizers.SGD(lr=.2, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn2.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.5),\n",
    "#               optimizer=Adam(lr=0.2),\n",
    "#               optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_test1=a2[:6533]\n",
    "# X_test_test1=a2[6533:]\n",
    "# y_train_test1=b2[:6533]\n",
    "# y_test_test1=b2[6533:]\n",
    "\n",
    "imgen_train = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "imgen_test=ImageDataGenerator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = imgen_train.flow(X_train_rescale, y_train_1hot, batch_size=64)\n",
    "test_generator = imgen_test.flow(X_test_rescale, y_test_1hot, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "101/101 [==============================] - 227s - loss: 2.1767 - acc: 0.3244 - val_loss: 2.3420 - val_acc: 0.1388\n",
      "Epoch 2/5\n",
      "101/101 [==============================] - 233s - loss: 1.7327 - acc: 0.4368 - val_loss: 2.3746 - val_acc: 0.1791\n",
      "Epoch 3/5\n",
      "101/101 [==============================] - 238s - loss: 1.5952 - acc: 0.4817 - val_loss: 2.2884 - val_acc: 0.2330\n",
      "Epoch 4/5\n",
      "101/101 [==============================] - 229s - loss: 1.4969 - acc: 0.5122 - val_loss: 2.2017 - val_acc: 0.3338\n",
      "Epoch 5/5\n",
      "101/101 [==============================] - 230s - loss: 1.4118 - acc: 0.5361 - val_loss: 2.1200 - val_acc: 0.3498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b87f94e0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn2.fit_generator(train_generator, steps_per_epoch=X_train_rescale.shape[0] // 64, epochs=5, \n",
    "                    validation_data=test_generator, validation_steps=len(y_test_1hot)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_image_dir='/Users/Dan/Desktop/new_image/all_flower_resize_new2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/.DS_Store'\n",
      "cannot reshape array of size 16320 into shape (120,136,3)\n",
      "cannot reshape array of size 12100 into shape (110,110,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/370.Ragged_robin.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot reshape array of size 9216 into shape (96,96,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/438.Spring_beauty.jpg'\n",
      "cannot reshape array of size 90000 into shape (300,300,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/472.Sunflower.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/725.Spring_beauty.jpg'\n",
      "cannot reshape array of size 2700 into shape (60,45,3)\n",
      "cannot reshape array of size 36936 into shape (216,171,3)\n",
      "cannot reshape array of size 13440 into shape (120,112,3)\n"
     ]
    }
   ],
   "source": [
    "image_list2=create_image_list(new_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_image_list(image_dir):\n",
    "    img_dataset=[]\n",
    "    label_dataset=[]\n",
    "    for img in os.listdir(image_dir):\n",
    "        try: \n",
    "            img_peth=str(image_dir)+'/'+str(img)\n",
    "            image_array=jpg_image_to_array(img_peth)\n",
    "            label=label_img(img)\n",
    "            img_dataset.append([image_array])  \n",
    "#             label_dataset.append([label])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     np.save('image_dataset.npy',img_dataset)\n",
    "#     return img_dataset\n",
    "    return img_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11755, 1, 100, 100, 3)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list2_arr=np.array(image_list2)\n",
    "image_list2_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11755, 100, 100, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_list2_reshape=image_list2_arr.reshape(11755,100,100,3)\n",
    "image_list2_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/.DS_Store'\n",
      "cannot reshape array of size 16320 into shape (120,136,3)\n",
      "cannot reshape array of size 12100 into shape (110,110,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/370.Ragged_robin.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot reshape array of size 9216 into shape (96,96,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/438.Spring_beauty.jpg'\n",
      "cannot reshape array of size 90000 into shape (300,300,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/472.Sunflower.jpg'\n",
      "cannot reshape array of size 7000 into shape (70,100,3)\n",
      "cannot identify image file '/Users/Dan/Desktop/new_image/all_flower_resize_new2/725.Spring_beauty.jpg'\n",
      "cannot reshape array of size 2700 into shape (60,45,3)\n",
      "cannot reshape array of size 36936 into shape (216,171,3)\n",
      "cannot reshape array of size 13440 into shape (120,112,3)\n"
     ]
    }
   ],
   "source": [
    "label_list2=create_label_list(new_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.fit(X_train_test1_rescale, y_train_test1_1hot, validation_split=.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, accuracy = cnn2.evaluate(X_test_test1_rescale, y_test_test1_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_label_list(image_dir):\n",
    "    img_dataset=[]\n",
    "    label_dataset=[]\n",
    "    for img in os.listdir(image_dir):\n",
    "        try: \n",
    "            img_peth=str(image_dir)+'/'+str(img)\n",
    "            image_array=jpg_image_to_array(img_peth)\n",
    "            label=label_img(img)\n",
    "#             img_dataset.append([image_array])  \n",
    "            label_dataset.append([label])\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "#     np.save('image_dataset.npy',img_dataset)\n",
    "#     return img_dataset\n",
    "    return label_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11755, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_list2_arr=np.array(label_list2)\n",
    "label_list2_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "aa = image_list2_arr\n",
    "bb = label_list2_arr\n",
    "\n",
    "cc = list(zip(aa, bb))\n",
    "\n",
    "random.shuffle(cc)\n",
    "\n",
    "aa1, bb1 = zip(*cc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f2(label_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa2=np.array(aa1)\n",
    "bb2=np.array(bb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11755, 100, 100, 3) (11755, 1)\n"
     ]
    }
   ],
   "source": [
    "aa2=aa2.reshape(11755, 100, 100, 3)\n",
    "print(aa2.shape,bb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9406.4"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11758*0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2=aa2[:9406]\n",
    "X_test2=aa2[9406:]\n",
    "y_train2=bb2[:9406]\n",
    "y_test2=bb2[9406:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train2_rescale=X_train2/255\n",
    "X_test2_rescale=X_test2/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_train_test1=a2[:6533]\n",
    "# X_test_test1=a2[6533:]\n",
    "# y_train_test1=b2[:6533]\n",
    "# y_test_test1=b2[6533:]\n",
    "\n",
    "imgen_train = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='constant'\n",
    ")\n",
    "\n",
    "imgen_test=ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = imgen_train.flow(X_train_test1_rescale, y_train_test1_1hot, batch_size=64)\n",
    "test_generator = imgen_test.flow(X_test_test1_rescale, y_test_test1_1hot, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn2.fit_generator(train_generator, steps_per_epoch=X_train_test1_rescale.shape[0] // 64, epochs=5, \n",
    "                    validation_data=test_generator, validation_steps=len(y_test_test1_1hot)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train2_1hot = encoder.fit_transform(y_train2)\n",
    "y_test2_1hot = encoder.fit_transform(y_test2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3 = Sequential([\n",
    "    Conv2D(50, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(150, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_17 (Conv2D)           (None, 98, 98, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 49, 49, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 47, 47, 100)       45100     \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               6771328   \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 6,819,118\n",
      "Trainable params: 6,819,118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn3.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.2),\n",
    "#               optimizer=Adam(lr=0.2),\n",
    "#               optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7524 samples, validate on 1882 samples\n",
      "Epoch 1/20\n",
      "7524/7524 [==============================] - 294s - loss: 1.9844 - acc: 0.2937 - val_loss: 2.0600 - val_acc: 0.2147\n",
      "Epoch 2/20\n",
      "7524/7524 [==============================] - 210s - loss: 1.6213 - acc: 0.4520 - val_loss: 1.6241 - val_acc: 0.4915\n",
      "Epoch 3/20\n",
      "7524/7524 [==============================] - 209s - loss: 1.4643 - acc: 0.5109 - val_loss: 1.6141 - val_acc: 0.4192\n",
      "Epoch 4/20\n",
      "7524/7524 [==============================] - 211s - loss: 1.3478 - acc: 0.5561 - val_loss: 1.4885 - val_acc: 0.5484\n",
      "Epoch 5/20\n",
      "7524/7524 [==============================] - 207s - loss: 1.2661 - acc: 0.5845 - val_loss: 1.4841 - val_acc: 0.4936\n",
      "Epoch 6/20\n",
      "7524/7524 [==============================] - 202s - loss: 1.2012 - acc: 0.6066 - val_loss: 1.3532 - val_acc: 0.5893\n",
      "Epoch 7/20\n",
      "7524/7524 [==============================] - 201s - loss: 1.1521 - acc: 0.6227 - val_loss: 1.3484 - val_acc: 0.5956\n",
      "Epoch 8/20\n",
      "7524/7524 [==============================] - 202s - loss: 1.0910 - acc: 0.6454 - val_loss: 1.3819 - val_acc: 0.5303\n",
      "Epoch 9/20\n",
      "7524/7524 [==============================] - 252s - loss: 1.0487 - acc: 0.6591 - val_loss: 1.3214 - val_acc: 0.6036\n",
      "Epoch 10/20\n",
      "7524/7524 [==============================] - 291s - loss: 0.9912 - acc: 0.6825 - val_loss: 1.2847 - val_acc: 0.5893\n",
      "Epoch 11/20\n",
      "7524/7524 [==============================] - 289s - loss: 0.9487 - acc: 0.6909 - val_loss: 1.2654 - val_acc: 0.6153\n",
      "Epoch 12/20\n",
      "7524/7524 [==============================] - 289s - loss: 0.9097 - acc: 0.7049 - val_loss: 1.3133 - val_acc: 0.5802\n",
      "Epoch 13/20\n",
      "7524/7524 [==============================] - 287s - loss: 0.8558 - acc: 0.7232 - val_loss: 1.2341 - val_acc: 0.6026\n",
      "Epoch 14/20\n",
      "7524/7524 [==============================] - 289s - loss: 0.8174 - acc: 0.7395 - val_loss: 1.2257 - val_acc: 0.5861\n",
      "Epoch 15/20\n",
      "7524/7524 [==============================] - 288s - loss: 0.7628 - acc: 0.7557 - val_loss: 1.1788 - val_acc: 0.6307\n",
      "Epoch 16/20\n",
      "7524/7524 [==============================] - 287s - loss: 0.7413 - acc: 0.7650 - val_loss: 1.2116 - val_acc: 0.6052\n",
      "Epoch 17/20\n",
      "7524/7524 [==============================] - 287s - loss: 0.7051 - acc: 0.7755 - val_loss: 1.1676 - val_acc: 0.6270\n",
      "Epoch 18/20\n",
      "7524/7524 [==============================] - 288s - loss: 0.6626 - acc: 0.7925 - val_loss: 1.1710 - val_acc: 0.6095\n",
      "Epoch 19/20\n",
      "7524/7524 [==============================] - 286s - loss: 0.6220 - acc: 0.8020 - val_loss: 1.1847 - val_acc: 0.6052\n",
      "Epoch 20/20\n",
      "7524/7524 [==============================] - 288s - loss: 0.5928 - acc: 0.8081 - val_loss: 1.2084 - val_acc: 0.6026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c40cef60>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn3.fit(X_train2_rescale, y_train2_1hot, validation_split=.2, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2349/2349 [==============================] - 26s    \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy3 = cnn3.evaluate(X_test2_rescale, y_test2_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69306087704504638"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4 = Sequential([\n",
    "    Conv2D(50, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(100,100,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    Conv2D(100, (3, 3), activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(150, (3, 3), activation='relu'),\n",
    "#     BatchNormalization(axis=-1),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "#     Conv2D(100, (3, 3), activation='relu'),\n",
    "#     Dropout(.25),\n",
    "#     MaxPool2D((2,2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dropout(.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 98, 98, 50)        1400      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 49, 49, 50)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 47, 47, 100)       45100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 47, 47, 100)       400       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 47, 47, 100)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 23, 23, 100)       0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 52900)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               6771328   \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 6,820,030\n",
      "Trainable params: 6,819,574\n",
      "Non-trainable params: 456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn4.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(lr=0.2),\n",
    "#               optimizer=Adam(lr=0.2),\n",
    "#               optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgen_train2 = ImageDataGenerator(\n",
    "    rotation_range=8,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    ")\n",
    "\n",
    "imgen_test2=ImageDataGenerator()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator2 = imgen_train2.flow(X_train2_rescale, y_train2_1hot, batch_size=64)\n",
    "test_generator2 = imgen_test2.flow(X_test2_rescale, y_test2_1hot, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10The history saving thread hit an unexpected error (OperationalError('unable to open database file',)).History will not be written to the database.\n",
      "\n",
      "146/146 [==============================] - 312s - loss: 1.3354 - acc: 0.5674 - val_loss: 1.4806 - val_acc: 0.5794\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 311s - loss: 1.3088 - acc: 0.5684 - val_loss: 1.6450 - val_acc: 0.5632\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 307s - loss: 1.2945 - acc: 0.5819 - val_loss: 1.5618 - val_acc: 0.5786\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 306s - loss: 1.2770 - acc: 0.5827 - val_loss: 1.5941 - val_acc: 0.5733\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 304s - loss: 1.2729 - acc: 0.5809 - val_loss: 1.6811 - val_acc: 0.5851\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 306s - loss: 1.2605 - acc: 0.5888 - val_loss: 1.5607 - val_acc: 0.5812\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 307s - loss: 1.2396 - acc: 0.5980 - val_loss: 1.3996 - val_acc: 0.5930\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 366s - loss: 1.2196 - acc: 0.6040 - val_loss: 1.6203 - val_acc: 0.5330\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 419s - loss: 1.2016 - acc: 0.6118 - val_loss: 1.3632 - val_acc: 0.5873\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 343s - loss: 1.1964 - acc: 0.6170 - val_loss: 1.3947 - val_acc: 0.5895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bc450470>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn4.fit_generator(train_generator2, steps_per_epoch=X_train2_rescale.shape[0] // 64, epochs=10, \n",
    "                    validation_data=test_generator2, validation_steps=len(y_test2_1hot)//64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
